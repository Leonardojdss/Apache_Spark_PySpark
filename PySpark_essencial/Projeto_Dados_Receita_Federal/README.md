# Fundamentos essenciais do Spark

Este notebook tem como objetivo desenvolver um projeto prático utilizando Apache Spark e PySpark para analisar dados da Receita Federal. Ele inclui etapas para configuração do ambiente, leitura e processamento dos dados, manipulação de DataFrames, execução de consultas SQL e visualização de resultados. O objetivo é demonstrar como utilizar PySpark para manipulação e análise de grandes volumes de dados, ilustrando o potencial do Apache Spark em aplicações de Big Data.
